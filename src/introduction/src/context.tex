%\section{Context}
The ever increasing complexity of aircraft and the market's depreciation of
single-core processors are motivating the introduction of multi-core processors
in aeronautical systems.

The operation of a safety critical system requires its certification by the
relevant authorities. This certification is obtained through a process in which
an applicant argues for the compliance of that system with regulation. The
introduction of a new category of hardware in such a system renders this process
particularly difficult, as it implies a lack of preexisting process for the
generation of a proof of compliance. Furthermore, the link between this new
hardware and the high level certification objectives may not be obvious.

For multi-core processors aboard an aircraft, the certification authorities
have published a set of guidelines (\cite{cast32A}) on low level certification
objectives that the applicant ought to prove their use of the multi-core
processor fulfills. This document does not, however, provide guidance on how to
obtain proof that these objectives are fulfilled, nor exactly what parts of the
multi-core processor may be involved in ensuring or impeding each of these
objectives.

The analysis of multi-core processors is made difficult by their inherently
parallel nature. Users have little control over the minutiae of the order in
which operations are performed. Furthermore, the users may not even be aware of
all the operations involved as, with few exceptions, the documentation provided
by the manufacturers is insufficient to properly understand the inner workings
of processor components. This is especially true in the case of some components
who have huge impacts on the processor's performance and for which the actual
behavior is kept secret, seemingly to avoid copy by a competing manufacturer.
While having the applicant manufacture their own processor would resolve this
issue, it is not economically viable in the aeronautical domain. Thus, the use
of preexisting commercially available components (\textit{Commercial
Off-The-Shelf}, \textit{COTS}) is prevalent.

Because of this lack of documentation despite their complexity, the behavior of
multi-core processors is generally conceived to be undeterministic, and its
features are deactivated in order to make executions more predictable. Indeed,
while mechanisms such as prefetching, out-of-order execution, and so many
others offer a very much welcomed improvement of performances in most cases,
they still can lead to decreased performances in some rare cases. To ascertain
compliance in all cases, applicants are expected to validate their programs
using their \textit{Worst Case Execution Time} (\textit{WCET}), which is
generally negatively impacted by such optimizations.

Cache coherence is one such optimization. In most cases, it speeds up access to
data used by multiple cores and ensures that the changes on the data performed
by one core are propagated to the others. This requires coordination between
the caches. This coordination is performed automatically and takes over the
fetching of data from the system's main memory. As a result, the speed at which
a core accesses data is dependent on the actions performed by the other cores.
Indeed, not only can the content of each core's cache be altered because of the
actions of another, but the speed at which each cache fetches data is dependent
on the data found in the other caches. This impact on the performance (and,
potentially, the correctness) of one core by the actions of another is called
\textit{interference}.

\todomsg{%
Interference w/o CTRL from user's bad. Breaks software isolation, can't just
analyze each software separately.
}

\todomsg{%
Cache Coordination is complex. Current works simply recommend disabling it.
With shared data between cores, that's pretty much either re-implementing it
yourself (error prone, costly, or non-COTS) or disabling caches (perf worse
than with a single core processor).
}

This thesis proposes a strategy that lets the applicant be aware of
the interference generated by cache coherence in a COTS multi-core system, thus
allowing them to take control of it so that they may prove their system to be
compliant despite its use of cache coherence.

This strategy is composed of three steps:
\todomsg{Turns these into something more like: the objective of this step
was to\ldots, also, mention that some of this stuff was published in a paper.}
\begin{itemize}
\item
The first step, presented in
Chapter~\ref{chap:identifying_cache_coherence}, is meant to ensure the
applicant is fully aware of all the peculiarities of the cache coherence
protocol implemented by the multi-core architecture of their choice. To achieve
this, the applicant is asked to start by formalizing what they believe the
cache coherence protocol to be, in a fashion that leaves no possible ambiguity.
This hypothetical cache coherence protocol ought to be proved correct prior to
its comparison with the one actually implemented by the platform. Indeed, this
comparison is done through a series of simple benchmarks which, by themselves,
would leave some gaps in the applicant's knowledge of the architecture's cache
coherence protocol. The hypothetical cache coherence protocol fills these gaps
with something that is at the very least plausibly what ought to have been
found.

\item
From the previous step, the applicant obtained an ambiguity-free cache
coherence protocol corresponding to the one used by the targeted multi-core
architecture. However, the analysis of the protocol by itself does not reveal
much. In Chapter~\ref{cha:modeling_cache_coherence}, the applicant is thus
invited to create a model of the cache coherence mechanisms in their entirety.
This thesis proposes a framework for the creation of such a model, basing
itself on networked timed automata. The components involved in maintaining
cache coherence all have their own automaton, letting the applicant model their
own system through the instantiation of the right amount of each type of
component as well as the setting of fairly basic parameters matching their
targeted architecture's documentation. Computer programs are also part of the
model, and are represented by sequences of instructions related to data
manipulation.

\item
The model created in the previous step can be used to perform an analysis of
the system. In this last step, Chapter~\ref{chap:exposing_interference}, are
proposed properties corresponding to the occurrence of interference, including
whether they had any impact, as well as some properties to measure said impact
on the execution time. Three types of interference are identified: Minor
interference, corresponding to the processing of other caches' queries without
impact on the studied cache; Demoting interference, where the studied cache
looses writing permissions because of another cache's query; and expelling
interference, where another cache's actions force the studied cache to evict a
memory element.
\end{itemize}
