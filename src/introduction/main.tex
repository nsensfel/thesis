\chapter{Introduction}
\definechapterdirectory{src/introduction}
%3 pages max.

\section{Context}
\subsection{Aeronautical Embedded Systems}
%\todomsg{Tres generic intro intro on embedded systems}
The ever increasing complexity of aircraft and the market's depreciation of
single-core processors are motivating the introduction of multi-core processors
in aeronautical systems.

The operation of a safety critical system requires its certification by the
relevant authorities. The entity applying to obtain this certification is refered
to as the \textit{applicant} in thesis. Indeed, this certification is obtained
through a process in which an applicant argues for the compliance of that
system with regulation. The introduction of a new category of hardware in such
a system renders this process particularly difficult, as it implies a lack of
preexisting process for the generation of a proof of compliance. Furthermore,
the link between this new hardware and the high level certification objectives
may not be obvious.

\subsection{Multi-core Based Systems Certification}
This thesis is part of the Phylog project. The objective of the Phylog project
is to provide tools that will help building a strong case for applicants
attempting to pass the certification process of an aeronautical computer
system.  These systems are assumed to be commercial off-the-shelf
(\textit{COTS}) products, meaning processors not manufacted solely for this
specific use.  The requirements that the applicants must prove this computer
system passes include those listed in the CAST-32A (\cite{cast32}). This
document focuses on the particularities of multi-core processors and the way
these particularities complicate the demonstration of both safety and
performance standard objectives fulfillment. Among the requirements listed in
the CAST-32A figures \textit{Resource Usage 3}, which requires the complete
identification of all interference and its effects with the chosen
configuration: \textit{The applicant has identified the interference channels
that could permit interference to affect the software applications hosted on
the MCP cores, and has verified the applicant's chosen means of mitigation of
the interference.} The Phylog project translated this requirement into an
assurance case, which can be seen in
Figure~\ref{fig:cast32a:ru3_assurance_case}.  To help applicants fulfill this
objective, this thesis focuses on interference generated by a prevalent feature
of multi-core
processors: cache coherence.

\begin{figure}[hbt!]
\resizebox{\textwidth}{!}{\input{\chapterdirectory/../second_intro/figure/RU3_diagram_new}}
\caption{Assurance Case Corresponding to RU3}
\label{fig:cast32a:ru3_assurance_case}
\end{figure}

\begin{definition}[Interference]
An interference is the unwarranted modification of the execution time of an
application because of the actions of another.
\end{definition}

\begin{figure}[hbt!]
\begin{center}
\includegraphics[width=0.6\textwidth]{\chapterdirectory/../second_intro/figure/demo_arch0.pdf}
\end{center}
\caption{Example of Interference}
\label{fig:second_intro:interference_example}
\end{figure}

\begin{example}[Example of Interference]
\label{ex:second_intro:interference}
In a system in which two cores, with one cache each, both attempting to send a
query to load data simultaneously, the interconnect will end up having to
choose one of the two queries to send first, and will put the other query in
waiting. This waiting lengthens the execution time of the associated
instruction and would not occur if there was no concurrent query, thus making
it an interference. Figure~\ref{fig:second_intro:interference_example}
illustrates this example, by having \textit{Cache 1}'s query be prevented
access to the interconnect during the other query's propagation, meaning that
the application running on \textit{Core 0} is interfering with the one running
on \textit{Core 1}.
\end{example}

%\input{\chapterdirectory/src/context.tex}

\section{The Issue of Cache Coherence}
\label{sec:intro:prob_statement}
When multiple cores make use of the same memory elements, separate copies of
these memory elements find themselves in different caches. As these copies are
separate, changes made to a copy are not reflected on the other copies. This
makes parallel computing difficult: a core might not be using the most
up-to-date value of the shared memory elements and the modifications it performs
might be blindly overridden by another core.

Cache coherence refers to mechanisms that will ensure all these separate copies
stay consistent. In effect, it will ensure that there is never an ambiguity on
the current value of memory elements, and that any core accessing a memory
element is using this most up-to-date value.

Achieving cache coherence requires caches to coordinate with each other. This
is done through shared buses, on which caches send queries to communicate needs
and receive data messages in reply. These buses in themselves are thus a
heavily used shared resource, making it a source of interference. However, the
main cause of cache coherence interference is that, to maintain coherence, these
queries can force caches to lose access to some of their content. As a result,
the actions of another core will determine whether a core can find the memory
element it wants through a quick cache access or if this will require a time
consuming fetch.

These cache coherence mechanisms are generally fully automated, meaning that
the application developers do not directly control when cache queries are made.
This makes predicting the emission and effects of these queries difficult.
Indeed, the emission of a query is determined by both program instruction and
the content of the cache, and the latter is subject to uncontrolled
modifications by queries emitted from other caches. This makes cache coherence
a source of important execution time variations and a challenge to
certification.

\section{Overview of the Thesis}
This thesis starts by introducing prerequisites: timed automata
(Chapter~\ref{cha:formal_methods}) and cache
coherence (Chapter~\ref{cha:cache_coherence}).
Once these have
been presented, the focus of this thesis can be explained in full
(Chapter~\ref{cha:second_intro}).
Indeed, The purpose of the thesis is to
develop a framework to ensure the applicant is made aware of the interference
generated by cache coherence in their chosen COTS multi-core processor.

To determine the state of the art and what specifically needs to be developed,
a whole part is dedicated to the relevant existing literature.
First is architecture profiling, for which existing solutions
relying on benchmarks are presented in Chapter~\ref{cha:micro-benchs}, including
works with a focus on caches. The current practices with regards to the use of
caches in multi-core employed in critical environments are detailed in
Chapter~\ref{cha:handling_it}. Since the solution proposed in this thesis
relies on formal methods, a number of existing works that have a similar
approach to the study of architectures are presented in
Chapter~\ref{cha:analyzing_rel_work}.

After clarifying what is left to be done to achieve a full framework that will
help with the cache coherence part of the certification, this thesis proposes
three contributions: a strategy to properly identify an architecture's cache
coherence protocol, a model template for multi-core architectures with cache
coherence support, and analyses to be performed on instantiated models in order
to expose the interference.
\begin{itemize}
\item
The first contribution, presented in
Chapter~\ref{chap:identifying_cache_coherence}, is meant to ensure the
applicant is fully aware of all the peculiarities of the cache coherence
protocol implemented by the multi-core architecture of their choice. To achieve
this, the applicant is asked to start by formalizing what they believe the
cache coherence protocol to be, in a fashion that leaves no possible ambiguity.
This hypothetical cache coherence protocol is then validated against the
architecture through observations made with micro-benchmarks.

\item
Using the previous contribution, the applicant obtained an ambiguity-free cache
coherence protocol corresponding to the one used by the targeted multi-core
architecture. However, the analysis of the protocol by itself does not reveal
much. The second contribution, presented in
Chapter~\ref{cha:modeling_cache_coherence}, proposes the model of a multi-core
architecture to the applicant. This model, made of networked timed automata, is
meant to be instantiated to fit the applicant's chosen architecture, and can
automatically be made to use the aforementioned ambiguity-free cache coherence
protocol.

\item
The instantiated model created using the previous contribution can be used to
perform an analysis of interference occurring in the system. This third
contribution, presented in Chapter~\ref{chap:exposing_interference}, shows how
model checking can be employed to expose the causes and effects of cache
coherence interference in the system. The analyzes include worst-case execution
time estimation, as well as the identification of how each program instruction
is affected by and/or generates interference.
\end{itemize}

